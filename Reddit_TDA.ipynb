{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600db403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# TDA libraries\n",
    "from ripser import ripser\n",
    "from persim import plot_diagrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c7db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "chunk_size = 100000\n",
    "G = nx.DiGraph()\n",
    "total_rows = sum(1 for _ in open('soc-redditHyperlinks-body.tsv')) - 1\n",
    "reader = pd.read_csv('soc-redditHyperlinks-body.tsv', sep='\\t', comment='#', chunksize=chunk_size)\n",
    "rows_processed = 0\n",
    "\n",
    "for chunk in reader:\n",
    "    for _, row in chunk.iterrows():\n",
    "        src = row['SOURCE_SUBREDDIT']\n",
    "        tgt = row['TARGET_SUBREDDIT']\n",
    "        # Add or update edge with weight\n",
    "        if G.has_edge(src, tgt):\n",
    "            G[src][tgt]['weight'] += 1\n",
    "        else:\n",
    "            G.add_edge(src, tgt, weight=1)\n",
    "    rows_processed += len(chunk)\n",
    "    print(f\"Processed {rows_processed}/{total_rows} rows ({rows_processed/total_rows:.2%})\")\n",
    "\n",
    "print(f\"Graph construction complete. Number of nodes: {G.number_of_nodes()}, Number of edges: {G.number_of_edges()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd578586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Graph Summary\")\n",
    "print(\"-------------\")\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "\n",
    "# Average degree (in and out)\n",
    "avg_in_degree = np.mean([d for n, d in G.in_degree()])\n",
    "avg_out_degree = np.mean([d for n, d in G.out_degree()])\n",
    "print(f\"Average in-degree: {avg_in_degree:.2f}\")\n",
    "print(f\"Average out-degree: {avg_out_degree:.2f}\")\n",
    "\n",
    "# Density\n",
    "print(f\"Density: {nx.density(G):.6f}\")\n",
    "\n",
    "# Top 5 nodes by in-degree\n",
    "top_in = sorted(G.in_degree(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"Top 5 nodes by in-degree:\")\n",
    "for node, deg in top_in:\n",
    "    print(f\"  {node}: {deg}\")\n",
    "\n",
    "# Top 5 nodes by out-degree\n",
    "top_out = sorted(G.out_degree(), key=lambda x: x[1], reverse=True)[:5]\n",
    "print(\"Top 5 nodes by out-degree:\")\n",
    "for node, deg in top_out:\n",
    "    print(f\"  {node}: {deg}\")\n",
    "\n",
    "# Edge weight statistics\n",
    "weights = [edata['weight'] for _, _, edata in G.edges(data=True)]\n",
    "print(f\"Edge weight stats: min={np.min(weights)}, max={np.max(weights)}, mean={np.mean(weights):.2f}, median={np.median(weights)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcdfb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from ripser import ripser\n",
    "from persim import plot_diagrams\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "nodes = list(G.nodes)[:200]\n",
    "subG = G.subgraph(nodes)\n",
    "\n",
    "# Compute shortest path distances (1/weight)\n",
    "distance_matrix = np.full((len(nodes), len(nodes)), np.inf)\n",
    "for i, u in enumerate(nodes):\n",
    "    lengths = nx.single_source_dijkstra_path_length(subG, u, weight=lambda u, v, d: 1/d['weight'])\n",
    "    for j, v in enumerate(nodes):\n",
    "        if v in lengths:\n",
    "            distance_matrix[i, j] = lengths[v]\n",
    "np.fill_diagonal(distance_matrix, 0)\n",
    "\n",
    "# Symmetrize: take min or max of (i,j) and (j,i)\n",
    "# Here, we use min (you can use max if you prefer)\n",
    "for i in range(len(nodes)):\n",
    "    for j in range(i+1, len(nodes)):\n",
    "        d = min(distance_matrix[i, j], distance_matrix[j, i])\n",
    "        distance_matrix[i, j] = d\n",
    "        distance_matrix[j, i] = d\n",
    "\n",
    "# Now convert to condensed form\n",
    "condensed_dist = squareform(distance_matrix)\n",
    "\n",
    "# Run persistent homology\n",
    "diagrams = ripser(distance_matrix, distance_matrix=True)['dgms']\n",
    "plot_diagrams(diagrams, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76ac19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# diagrams[1] is H1 (loops), diagrams[0] is H0 (components)\n",
    "H1 = diagrams[1]\n",
    "persistences = H1[:,1] - H1[:,0]\n",
    "# Get indices of top k most persistent features (outliers)\n",
    "k = 3  # or any number you want\n",
    "outlier_indices = np.argsort(persistences)[-k:]\n",
    "outlier_features = H1[outlier_indices]\n",
    "print(\"Top persistent H1 features (birth, death, persistence):\")\n",
    "for i, idx in enumerate(outlier_indices):\n",
    "    print(f\"{i+1}: Birth={H1[idx,0]:.3f}, Death={H1[idx,1]:.3f}, Persistence={persistences[idx]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Get the birth value of the most persistent H1 feature\n",
    "most_persistent_idx = outlier_indices[-1]\n",
    "birth_value = H1[most_persistent_idx, 0]\n",
    "\n",
    "# Threshold the distance matrix at the birth value\n",
    "threshold = birth_value + 1e-8  # small epsilon to include edges at birth\n",
    "adjacency = (distance_matrix <= threshold).astype(int)\n",
    "\n",
    "# Build the thresholded undirected graph\n",
    "G_thresh = nx.Graph()\n",
    "for i in range(len(nodes)):\n",
    "    for j in range(i+1, len(nodes)):\n",
    "        if adjacency[i, j]:\n",
    "            G_thresh.add_edge(nodes[i], nodes[j])\n",
    "\n",
    "# Find all cycles in the thresholded graph\n",
    "# For large graphs, you may want to use nx.cycle_basis for efficiency\n",
    "cycles = nx.cycle_basis(G_thresh)\n",
    "\n",
    "# Print the largest cycle (as a proxy for the persistent feature)\n",
    "if cycles:\n",
    "    print(\"Nodes (subreddits) in a representative cycle for the most persistent H1 feature:\")\n",
    "    print(cycles[0])\n",
    "else:\n",
    "    print(\"No cycles found at this threshold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import gudhi as gd\n",
    "\n",
    "# Assume G is your weighted DiGraph and nodes is your list of subreddits\n",
    "nodes = list(G.nodes)[:200]\n",
    "subG = G.subgraph(nodes)\n",
    "\n",
    "# Compute the symmetric shortest-path distance matrix\n",
    "distance_matrix = np.full((len(nodes), len(nodes)), np.inf)\n",
    "for i, u in enumerate(nodes):\n",
    "    lengths = nx.single_source_dijkstra_path_length(subG, u, weight=lambda u, v, d: 1/d['weight'])\n",
    "    for j, v in enumerate(nodes):\n",
    "        if v in lengths:\n",
    "            distance_matrix[i, j] = lengths[v]\n",
    "np.fill_diagonal(distance_matrix, 0)\n",
    "# Symmetrize\n",
    "for i in range(len(nodes)):\n",
    "    for j in range(i+1, len(nodes)):\n",
    "        d = min(distance_matrix[i, j], distance_matrix[j, i])\n",
    "        distance_matrix[i, j] = d\n",
    "        distance_matrix[j, i] = d\n",
    "# Replace inf/nan with large finite value\n",
    "finite_distances = distance_matrix[np.isfinite(distance_matrix)]\n",
    "max_dist = np.max(finite_distances)\n",
    "large_value = 2 * max_dist\n",
    "distance_matrix[~np.isfinite(distance_matrix)] = large_value\n",
    "\n",
    "# Build the Rips complex\n",
    "rips_complex = gd.RipsComplex(distance_matrix=distance_matrix, max_edge_length=max_dist)\n",
    "simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "\n",
    "# Compute persistence (no extra arguments needed)\n",
    "diag = simplex_tree.persistence(homology_coeff_field=2, persistence_dim_max=True)\n",
    "\n",
    "# Extract H1 (loops) features and their representatives\n",
    "H1_loops = [(i, p) for i, p in enumerate(diag) if p[0] == 1 and p[1][1] < float('inf')]\n",
    "print(\"Top H1 features (loops):\")\n",
    "for idx, (dim, (birth, death)) in H1_loops:\n",
    "    print(f\"Feature {idx}: Birth={birth:.3f}, Death={death:.3f}, Persistence={death-birth:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for simplex, filtration_value in simplex_tree.get_filtration():\n",
    "    subreddit_names = [nodes[i] for i in simplex]\n",
    "    print(subreddit_names, filtration_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320bce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Convert to undirected graph for clique analysis\n",
    "G_undirected = G.to_undirected()\n",
    "\n",
    "# Find all maximal cliques (each is a list of nodes)\n",
    "cliques = list(nx.find_cliques(G_undirected))\n",
    "\n",
    "# Find all connected components\n",
    "components = list(nx.connected_components(G_undirected))\n",
    "\n",
    "# For each clique, check if it is a connected component (i.e., isolated)\n",
    "isolated_cliques = []\n",
    "for clique in cliques:\n",
    "    clique_set = set(clique)\n",
    "    # Check if this clique is a connected component and not part of a larger component\n",
    "    if clique_set in components and len(clique) > 1:  # Only non-trivial cliques\n",
    "        isolated_cliques.append(clique)\n",
    "\n",
    "# Print results\n",
    "if isolated_cliques:\n",
    "    print(\"Isolated maximal cliques (tightly connected groups not connected to anything else):\")\n",
    "    for idx, clique in enumerate(isolated_cliques, 1):\n",
    "        print(f\"Clique {idx} (size {len(clique)}): {clique}\")\n",
    "else:\n",
    "    print(\"No isolated maximal cliques found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be4c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Convert to undirected graph for clique analysis\n",
    "G_undirected = G.to_undirected()\n",
    "\n",
    "# Find all maximal cliques\n",
    "cliques = list(nx.find_cliques(G_undirected))\n",
    "\n",
    "def clique_strength(clique, G):\n",
    "    weights = []\n",
    "    for i in range(len(clique)):\n",
    "        for j in range(i+1, len(clique)):\n",
    "            u, v = clique[i], clique[j]\n",
    "            if G.has_edge(u, v):\n",
    "                w = G[u][v].get('weight', 1)\n",
    "                weights.append(w)\n",
    "    if weights:\n",
    "        return np.mean(weights)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Compute strength for all cliques of size > 2\n",
    "clique_strengths = []\n",
    "for clique in cliques:\n",
    "    if len(clique) > 2:\n",
    "        strength = clique_strength(clique, G_undirected)\n",
    "        clique_strengths.append((clique, strength))\n",
    "\n",
    "# Sort by strength descending and print top 10\n",
    "top_cliques = sorted(clique_strengths, key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(\"Top 10 cliques by average edge weight:\")\n",
    "for idx, (clique, strength) in enumerate(top_cliques, 1):\n",
    "    print(f\"{idx}. Size: {len(clique)}, Strength: {strength:.2f}, Subreddits: {clique}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b20060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Subsample: pick 30 random nodes\n",
    "sample_size = 30\n",
    "sample_nodes = random.sample(list(G.nodes), sample_size)\n",
    "subG = G.subgraph(sample_nodes).to_undirected()\n",
    "\n",
    "# Find cliques in the subsample\n",
    "cliques = list(nx.find_cliques(subG))\n",
    "largest_clique = max(cliques, key=len) if cliques else []\n",
    "\n",
    "# Draw the subsample\n",
    "plt.figure(figsize=(8, 6))\n",
    "pos = nx.spring_layout(subG, seed=42)\n",
    "nx.draw(subG, pos, node_color='lightblue', with_labels=True, node_size=300, edge_color='gray', alpha=0.7)\n",
    "\n",
    "# Highlight the largest clique in red\n",
    "if largest_clique:\n",
    "    nx.draw_networkx_nodes(subG, pos, nodelist=largest_clique, node_color='red', node_size=400)\n",
    "    nx.draw_networkx_edges(subG, pos, edgelist=[(u, v) for u in largest_clique for v in largest_clique if u != v and subG.has_edge(u, v)], edge_color='red', width=2)\n",
    "plt.title(\"Random Subsample of Reddit Graph with Largest Clique Highlighted\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84a7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gudhi as gd\n",
    "\n",
    "# Build a distance matrix for the subsample\n",
    "nodes_sub = list(subG.nodes)\n",
    "n = len(nodes_sub)\n",
    "distance_matrix = np.full((n, n), np.inf)\n",
    "for i, u in enumerate(nodes_sub):\n",
    "    lengths = nx.single_source_dijkstra_path_length(subG, u, weight=lambda u, v, d: 1/d.get('weight', 1))\n",
    "    for j, v in enumerate(nodes_sub):\n",
    "        if v in lengths:\n",
    "            distance_matrix[i, j] = lengths[v]\n",
    "np.fill_diagonal(distance_matrix, 0)\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        d = min(distance_matrix[i, j], distance_matrix[j, i])\n",
    "        distance_matrix[i, j] = d\n",
    "        distance_matrix[j, i] = d\n",
    "finite_distances = distance_matrix[np.isfinite(distance_matrix)]\n",
    "max_dist = np.max(finite_distances)\n",
    "large_value = 2 * max_dist\n",
    "distance_matrix[~np.isfinite(distance_matrix)] = large_value\n",
    "\n",
    "# Build Rips complex and simplex tree\n",
    "rips_complex = gd.RipsComplex(distance_matrix=distance_matrix, max_edge_length=max_dist)\n",
    "simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "\n",
    "# Extract edges and triangles\n",
    "edges = []\n",
    "triangles = []\n",
    "for simplex, filtration in simplex_tree.get_filtration():\n",
    "    if len(simplex) == 2:\n",
    "        edges.append(tuple(simplex))\n",
    "    elif len(simplex) == 3:\n",
    "        triangles.append(tuple(simplex))\n",
    "\n",
    "# Map indices to subreddit names\n",
    "edges_named = [(nodes_sub[i], nodes_sub[j]) for i, j in edges]\n",
    "triangles_named = [(nodes_sub[i], nodes_sub[j], nodes_sub[k]) for i, j, k in triangles]\n",
    "\n",
    "# Visualize\n",
    "G_simplex = nx.Graph()\n",
    "G_simplex.add_edges_from(edges_named)\n",
    "plt.figure(figsize=(8, 6))\n",
    "pos = nx.spring_layout(G_simplex, seed=42)\n",
    "nx.draw_networkx_edges(G_simplex, pos, alpha=0.3)\n",
    "nx.draw_networkx_nodes(G_simplex, pos, node_size=50, alpha=0.7)\n",
    "for triangle in triangles_named:\n",
    "    pts = [pos[n] for n in triangle]\n",
    "    polygon = plt.Polygon(pts, closed=True, fill=True, color='orange', alpha=0.2)\n",
    "    plt.gca().add_patch(polygon)\n",
    "plt.title(\"Simplex Tree (1-skeleton and triangles) for Subsample\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba96c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import gudhi as gd\n",
    "\n",
    "# 1. Larger subsample\n",
    "sample_size = 100\n",
    "sample_nodes = random.sample(list(G.nodes), sample_size)\n",
    "subG = G.subgraph(sample_nodes).to_undirected()\n",
    "\n",
    "# 2. Build distance matrix\n",
    "nodes_sub = list(subG.nodes)\n",
    "n = len(nodes_sub)\n",
    "distance_matrix = np.full((n, n), np.inf)\n",
    "for i, u in enumerate(nodes_sub):\n",
    "    lengths = nx.single_source_dijkstra_path_length(subG, u, weight=lambda u, v, d: 1/d.get('weight', 1))\n",
    "    for j, v in enumerate(nodes_sub):\n",
    "        if v in lengths:\n",
    "            distance_matrix[i, j] = lengths[v]\n",
    "np.fill_diagonal(distance_matrix, 0)\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        d = min(distance_matrix[i, j], distance_matrix[j, i])\n",
    "        distance_matrix[i, j] = d\n",
    "        distance_matrix[j, i] = d\n",
    "finite_distances = distance_matrix[np.isfinite(distance_matrix)]\n",
    "max_dist = np.max(finite_distances)\n",
    "large_value = 2 * max_dist\n",
    "distance_matrix[~np.isfinite(distance_matrix)] = large_value\n",
    "\n",
    "# 3. Use a much larger filtration threshold\n",
    "rips_complex = gd.RipsComplex(distance_matrix=distance_matrix, max_edge_length=10 * max_dist)\n",
    "simplex_tree = rips_complex.create_simplex_tree(max_dimension=2)\n",
    "\n",
    "# 4. Count simplices by dimension\n",
    "simplex_counts = {}\n",
    "for simplex, filtration in simplex_tree.get_filtration():\n",
    "    dim = len(simplex) - 1\n",
    "    simplex_counts[dim] = simplex_counts.get(dim, 0) + 1\n",
    "\n",
    "print(\"Number of simplices by dimension:\")\n",
    "for dim in sorted(simplex_counts):\n",
    "    print(f\"Dimension {dim}: {simplex_counts[dim]}\")\n",
    "\n",
    "# 5. Extract edges and triangles for visualization\n",
    "edges = []\n",
    "triangles = []\n",
    "for simplex, filtration in simplex_tree.get_filtration():\n",
    "    if len(simplex) == 2:\n",
    "        edges.append(tuple(simplex))\n",
    "    elif len(simplex) == 3:\n",
    "        triangles.append(tuple(simplex))\n",
    "\n",
    "edges_named = [(nodes_sub[i], nodes_sub[j]) for i, j in edges]\n",
    "triangles_named = [(nodes_sub[i], nodes_sub[j], nodes_sub[k]) for i, j, k in triangles]\n",
    "\n",
    "G_simplex = nx.Graph()\n",
    "G_simplex.add_edges_from(edges_named)\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.spring_layout(G_simplex, seed=42)\n",
    "nx.draw_networkx_edges(G_simplex, pos, alpha=0.3)\n",
    "nx.draw_networkx_nodes(G_simplex, pos, node_size=50, alpha=0.7)\n",
    "for triangle in triangles_named:\n",
    "    pts = [pos[n] for n in triangle]\n",
    "    polygon = plt.Polygon(pts, closed=True, fill=True, color='orange', alpha=0.2)\n",
    "    plt.gca().add_patch(polygon)\n",
    "plt.title(\"Detailed Simplex Tree (1-skeleton and triangles) for Larger Subsample and Higher Threshold\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40243108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G_undirected = G.to_undirected()\n",
    "cliques = list(nx.find_cliques(G_undirected))\n",
    "\n",
    "results = []\n",
    "for clique in cliques:\n",
    "    if len(clique) > 2:\n",
    "        in_count = 0\n",
    "        out_count = 0\n",
    "        for node in clique:\n",
    "            in_edges = [src for src in G.predecessors(node) if src not in clique]\n",
    "            in_count += len(in_edges)\n",
    "            out_edges = [tgt for tgt in G.successors(node) if tgt not in clique]\n",
    "            out_count += len(out_edges)\n",
    "        results.append({\n",
    "            'clique': clique,\n",
    "            'in_count': in_count,\n",
    "            'out_count': out_count,\n",
    "            'size': len(clique)\n",
    "        })\n",
    "\n",
    "sorted_results = sorted(results, key=lambda x: (-x['in_count'], x['out_count']))\n",
    "\n",
    "print(\"Cliques with many incoming and few outgoing edges:\")\n",
    "for entry in sorted_results[:10]:\n",
    "    print(f\"Clique (size {entry['size']}): {entry['clique']}\")\n",
    "    print(f\"  Incoming edges from outside: {entry['in_count']}\")\n",
    "    print(f\"  Outgoing edges to outside: {entry['out_count']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e227ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by in_count (ascending), then out_count (ascending)\n",
    "sorted_insulated = sorted(results, key=lambda x: (x['in_count'], x['out_count']))\n",
    "\n",
    "print(\"Top 10 most insulated cliques (fewest incoming, then fewest outgoing edges):\")\n",
    "for entry in sorted_insulated[:10]:\n",
    "    print(f\"Clique (size {entry['size']}): {entry['clique']}\")\n",
    "    print(f\"  Incoming edges from outside: {entry['in_count']}\")\n",
    "    print(f\"  Outgoing edges to outside: {entry['out_count']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac65850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Convert to undirected for clique finding\n",
    "G_undirected = G.to_undirected()\n",
    "cliques = list(nx.find_cliques(G_undirected))\n",
    "\n",
    "diff_results = []\n",
    "for clique in cliques:\n",
    "    if len(clique) > 2:  # Only consider non-trivial cliques\n",
    "        in_count = 0\n",
    "        out_count = 0\n",
    "        for node in clique:\n",
    "            # Incoming: from outside to inside\n",
    "            in_edges = [src for src in G.predecessors(node) if src not in clique]\n",
    "            in_count += len(in_edges)\n",
    "            # Outgoing: from inside to outside\n",
    "            out_edges = [tgt for tgt in G.successors(node) if tgt not in clique]\n",
    "            out_count += len(out_edges)\n",
    "        diff = in_count - out_count\n",
    "        diff_results.append({\n",
    "            'clique': clique,\n",
    "            'in_count': in_count,\n",
    "            'out_count': out_count,\n",
    "            'diff': diff,\n",
    "            'size': len(clique)\n",
    "        })\n",
    "\n",
    "# Sort by greatest difference (in_count - out_count), descending\n",
    "sorted_diff = sorted(diff_results, key=lambda x: x['diff'], reverse=True)\n",
    "\n",
    "print(\"Top 10 cliques by greatest difference between incoming and outgoing edges (in - out):\")\n",
    "for entry in sorted_diff[:10]:\n",
    "    print(f\"Clique (size {entry['size']}): {entry['clique']}\")\n",
    "    print(f\"  Incoming edges from outside: {entry['in_count']}\")\n",
    "    print(f\"  Outgoing edges to outside: {entry['out_count']}\")\n",
    "    print(f\"  Difference (in - out): {entry['diff']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e417cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Set your desired maximum clique size\n",
    "max_clique_size = 3  # Change this to whatever maximum size you want\n",
    "\n",
    "G_undirected = G.to_undirected()\n",
    "cliques = list(nx.find_cliques(G_undirected))\n",
    "\n",
    "diff_results = []\n",
    "for clique in cliques:\n",
    "    if 2 < len(clique) <= max_clique_size:  # Only consider cliques within size range\n",
    "        in_count = 0\n",
    "        out_count = 0\n",
    "        for node in clique:\n",
    "            # Incoming: from outside to inside\n",
    "            in_edges = [src for src in G.predecessors(node) if src not in clique]\n",
    "            in_count += len(in_edges)\n",
    "            # Outgoing: from inside to outside\n",
    "            out_edges = [tgt for tgt in G.successors(node) if tgt not in clique]\n",
    "            out_count += len(out_edges)\n",
    "        diff = in_count - out_count\n",
    "        diff_results.append({\n",
    "            'clique': clique,\n",
    "            'in_count': in_count,\n",
    "            'out_count': out_count,\n",
    "            'diff': diff,\n",
    "            'size': len(clique)\n",
    "        })\n",
    "\n",
    "# Sort by greatest difference (in_count - out_count), descending\n",
    "sorted_diff = sorted(diff_results, key=lambda x: x['diff'], reverse=True)\n",
    "\n",
    "print(f\"Top 10 cliques (max size {max_clique_size}) by greatest difference between incoming and outgoing edges (in - out):\")\n",
    "for entry in sorted_diff[:10]:\n",
    "    print(f\"Clique (size {entry['size']}): {entry['clique']}\")\n",
    "    print(f\"  Incoming edges from outside: {entry['in_count']}\")\n",
    "    print(f\"  Outgoing edges to outside: {entry['out_count']}\")\n",
    "    print(f\"  Difference (in - out): {entry['diff']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0badb55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Top 10 cliques (max size {max_clique_size}) by greatest difference between incoming and outgoing edges (in - out):\")\n",
    "for entry in sorted_diff[:50]:\n",
    "    print(f\"Clique (size {entry['size']}): {entry['clique']}\")\n",
    "    print(f\"  Incoming edges from outside: {entry['in_count']}\")\n",
    "    print(f\"  Outgoing edges to outside: {entry['out_count']}\")\n",
    "    print(f\"  Difference (in - out): {entry['diff']}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
